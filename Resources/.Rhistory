install.packages("tidyverse")
install.packages("jsonlite")
# Call the function with the student vector as an argument.
print(students)
# Part I
students <- c()
# Call the function with the student vector as an argument.
print(students_vector)
print(Sys.Date())
# Create a for loop
for (meh in roll_call) {
print(meh)
}
# Create a for loop
for (meh in roll_call) {
print(meh)
}
roll_call <- function(class){
# Part I
students <- c()
print(Sys.Date())
# Create a for loop
for (meh in roll_call) {
print(meh)
}
# Call the function with the student vector as an argument.
print(students)
# Part I
students <- c()
print(Sys.Date())
?sample_n()
?sample_n()
?sample_n()
?sample_n()
install.packages(sample_n)
library("sample_n")
?sample_n()
?sample_n()
setwd("~/KU Data Analytics Boot Camp/Classwork/Module 15/15.2.3")
?sample_n()
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
setwd("~/KU Data Analytics Boot Camp/Classwork/Module 15/Resources")
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
library(ggplot2)
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
library(dplyr)
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
population_table <- read.csv('used_car_data.csv',check.names = F,stringsAsFactors = F) #import used car dataset
plt <- ggplot(population_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
sample_table <- population_table %>% sample_n(50) #randomly sample 50 data points
plt <- ggplot(sample_table,aes(x=log10(Miles_Driven))) #import dataset into ggplot2
plt + geom_density() #visualize distribution using density plot
?t.test()
t.test(log10(sample_table$Miles_Driven),mu=mean(log10(population_table$Miles_Driven))) #compare sample versus population means
sample_table <- population_table %>% sample_n(50) #generate 50 randomly sampled data points
sample_table2 <- population_table %>% sample_n(50) #generate another 50 randomly sampled data points
t.test(log10(sample_table$Miles_Driven),log10(sample_table2$Miles_Driven)) #compare means of two samples
?t.test()
mpg_data <- read.csv('mpg_modified.csv') #import dataset
mpg_1999 <- mpg_data %>% filter(year==1999) #select only data points where the year is 1999
mpg_2008 <- mpg_data %>% filter(year==2008) #select only data points where the year is 2008
t.test(mpg_1999$hwy,mpg_2008$hwy,paired = T) #compare the mean difference between two samples
?aov()
#cleaning data
mtcars_filt <- mtcars[,c("hp","cyl")] #filter columns from mtcars dataset
mtcars_filt$cyl <- factor(mtcars_filt$cyl) #convert numeric column to factor
aov(hp ~ cyl,data=mtcars_filt) #compare means across multiple levels
#how to get p-value from aov function
summary(aov(hp ~ cyl,data=mtcars_filt))
?cor()
head(mtcars)
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() #create scatter plot
cor(mtcars$hp,mtcars$qsec) #calculate correlation coefficient
used_cars <- read.csv('used_car_data.csv',stringsAsFactors = F) #read in dataset
head(used_cars)
plt <- ggplot(used_cars,aes(x=Miles_Driven,y=Selling_Price)) #import dataset into ggplot2
plt + geom_point() #create a scatter plot
cor(used_cars$Miles_Driven,used_cars$Selling_Price) #calculate correlation coefficient
used_matrix <- as.matrix(used_cars[,c("Selling_Price","Present_Price","Miles_Driven")]) #convert data frame into numeric matrix
cor(used_matrix)
?lm()
lm(qsec ~ hp,mtcars) #create linear model
summary(lm(qsec~hp,mtcars)) #summarize linear model
model <- lm(qsec ~ hp,mtcars) #create linear model
yvals <- model$coefficients['hp']*mtcars$hp +
model$coefficients['(Intercept)'] #determine y-axis values from linear model
model <- lm(qsec ~ hp,mtcars) #create linear model
yvals <- model$coefficients['hp']*mtcars$hp +
model$coefficients['(Intercept)'] #determine y-axis values from linear model
plt <- ggplot(mtcars,aes(x=hp,y=qsec)) #import dataset into ggplot2
plt + geom_point() + geom_line(aes(y=yvals), color = "red") #plot scatter and linear model
lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars) #generate multiple linear regression model
summary(lm(qsec ~ mpg + disp + drat + wt + hp,data=mtcars)) #generate summary statistics
?chisq.test()
#build our contingency table
table(mpg$class,mpg$year) #generate contingency table
#  pass the contingency table to the chisq.test()function
tbl <- table(mpg$class,mpg$year) #generate contingency table
chisq.test(tbl) #compare categorical distributions
setwd("~/KU Data Analytics Boot Camp/Classwork/Module 15/MechaCar_Statistical_Analysis/Resources")
library(dplyr)
mecha_car <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD + mpg,data=mecha_car) #generate multiple linear regression model
lm(mpg ~ vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD + mpg,data=mecha_car) #generate multiple linear regression model
View(mecha_car)
View(mecha_car)
library(dplyr)
mecha_car <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD + mpg,data=mecha_car) #generate multiple linear regression model
library(dplyr)
mecha_car <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD + mpg,data=mecha_car) #generate multiple linear regression model
lm(mpg ~ vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD,data=mecha_car) #generate multiple linear regression model
library(dplyr)
mecha_car <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
lm(mpg ~ vehicle_length + Vehicle_weight + spoiler_angle + ground_clearance + AWD,data=mecha_car) #generate multiple linear regression model
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=mecha_car) #generate multiple linear regression model
#3. Use the library() function to load the dplyr package.
library(dplyr)
#4. Import and read in the MechaCar_mpg.csv file as a dataframe.
mecha_car <- read.csv(file='MechaCar_mpg.csv',check.names=F,stringsAsFactors = F)
#5. Perform linear regression using the lm() function.
lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=mecha_car)
#6. Using the summary() function, determine the p-value and the r-squared value for the linear regression model.
summary(lm(mpg ~ vehicle_length + vehicle_weight + spoiler_angle + ground_clearance + AWD,data=mecha_car))
# Deliverable 2
#2. Import and read in the Suspension_Coil.csv file as a table.
suspension_coil <- read.csv(file='Suspension_Coil.csv',check.names=F,stringsAsFactors = F)
?read.csv()
summary(lm(qsec~hp,mtcars)) #summarize linear model
summary(lm(qsec~hp,mtcars)) #summarize linear model
#3. create a total_summary dataframe using the summarize() function to get the mean, median, variance,
#and standard deviation of the suspension coil’s PSI column.
total_summary <- suspension_coil %>% Summarize(,suspension_coil)
# Deliverable 2
#2. Import and read in the Suspension_Coil.csv file as a table.
suspension_coil <- read.csv(file='Suspension_Coil.csv',check.names=F,stringsAsFactors = F)
View(suspension_coil)
View(suspension_coil)
#3. create a total_summary dataframe using the summarize() function to get the mean, median, variance,
#and standard deviation of the suspension coil’s PSI column.
total_summary <- suspension_coil %>% Summarize(Mean_Mileage=mean(PSI))
#3. create a total_summary dataframe using the summarize() function to get the mean, median, variance,
#and standard deviation of the suspension coil’s PSI column.
total_summary <- suspension_coil %>% summarize(mean_psi=mean(PSI), median_psi=median(PSI), variance_psi=var(PSI))
#3. create a total_summary dataframe using the summarize() function to get the mean, median, variance,
#and standard deviation of the suspension coil’s PSI column.
total_summary <- suspension_coil %>% summarize(mean_psi=mean(PSI), median_psi=median(PSI), variance_psi=var(PSI), stdev=sd(PSI))
head(totat_summary)
head(total_summary)
(total_summary)
View(total_summary)
mpg_summary <- mpg %>% group_by(manufacturer) %>% summarize(Vehicle_Count=n(), .groups = 'keep')
(lot_summary)
(total_summary)
(lot_summary)
#4 create a lot_summary dataframe using the group_by() and the summarize() functions to group each manufacturing lot by the mean, median, variance,
# and standard deviation of the suspension coil’s PSI column.
lot_summary <- suspension_coil %>% group_by(mean_psi=mean(PSI), median_psi=median(PSI), variance_psi=var(PSI), stdev=sd(PSI))
View(lot_summary)
View(lot_summary)
(lot_summary)
#4 create a lot_summary dataframe using the group_by() and the summarize() functions to group each manufacturing lot by the mean, median, variance,
# and standard deviation of the suspension coil’s PSI column.
lot_summary <- suspension_coil %>% group_by(mean_psi=mean(PSI), median_psi=median(PSI), variance_psi=var(PSI), stdev=sd(PSI))  %>% summarize(Vehicle_Count=n(), .groups = 'keep')
(lot_summary)
View(lot_summary)
#4 create a lot_summary dataframe using the group_by() and the summarize() functions to group each manufacturing lot by the mean, median, variance,
# and standard deviation of the suspension coil’s PSI column.
lot_summary <- suspension_coil %>% group_by(Manufacturing_Lot) %>% summarize(mean_psi=mean(PSI), median_psi=median(PSI), variance_psi=var(PSI), stdev=sd(PSI), .groups = 'keep')
(lot_summary)
View(lot_summary)
View(lot_summary)
View(lot_summary)
View(lot_summary)
View(total_summary)
#Deliverable 3
#1 Determine if the PSI across all manufacturing lots is statistically different from the population mean of 1,500 pounds per square inch.
t.test(suspension_coil$PSI, mu=1500)
?t.test()
?t.test()
#2 Determine if the PSI for each manufacturing lot is statistically different from the population mean of 1,500 pounds per square inch.
t.test(subset(suspension_coil, Manufacturing_Lot=='Lot 1')$PSI, mu=1500)
#2 Determine if the PSI for each manufacturing lot is statistically different from the population mean of 1,500 pounds per square inch.
t.test(subset(suspension_coil, Manufacturing_Lot=='Lot1')$PSI, mu=1500)
t.test(subset(suspension_coil, Manufacturing_Lot=='Lot2')$PSI, mu=1500)
t.test(subset(suspension_coil, Manufacturing_Lot=='Lot3')$PSI, mu=1500)
#Deliverable 3
#1 Determine if the PSI across all manufacturing lots is statistically different from the population mean of 1,500 pounds per square inch.
t.test(suspension_coil$PSI, mu=1500)
